在本实验中, 你需要构建```Raft```, 一个复制状态机的协议.

在下个实验中, 你将在```Raft```之上构建一个```key/value```服务. 然后, 你将服务分片到多个复制的状态机以获得更高的性能.

```raft```将客户端请求组织为一个日志序列, 并确保所有副本服务器有相同的日志. 每个副本按照日志顺序执行客户端的请求, 并应用到服务状态的本地副本上. 如果

### The code

​	在```raft/raft.go```中添加代码以实现```raft```. 在该文件中，您将找到框架代码，以及如何发送和接收rpc的示例。

​	您的实现必须支持以下接口，测试代码和(最终)您的键值对服务将使用该接口。你可以在```raft.go```的注释中找到更多细节。

```go
// create a new Raft server instance:
rf := Make(peers, me, persister, applyCh)

// start agreement on a new log entry:
rf.Start(command interface{}) (index, term, isleader)

// ask a Raft for its current term, and whether it thinks it is leader
rf.GetState() (term, isLeader)

// each time a new entry is committed to the log, each Raft peer
// should send an ApplyMsg to the service (or tester).
type ApplyMsg
```

​	一个服务调用```make(peers, me, ...)```来创建一个```Raft peer```.

​	其中```peers```参数是一个网络表示符数组, 用于```rpc```. ```me```参数是该节点在```peers```数组的索引.

​	```start(command)```要求```raft```启动处理, 将命令附加到复制的日志中. ```start```应该立即返回而无需等待日志追加完成. 但是你需要为每个已提交的日志条目发送一个```ApplyMsg```到```applyCh```信道.

​	```raft.go```包含了发送一个```rpc```的示例代码. 你的```raft peers```应该使用```src/labrpc```中的```rpc```代码. 该```labrpc```进行延迟, 重排序, 丢弃等操作来模拟各种网络故障.

​	后续的实验都是在这个实验的基础上进行的, 所以编写可靠的代码非常重要.

#### 领导人完整特性证明

采用反证法. 假设任期T的领导人在它的任期提交了一条新日志, 但这条日志没有存储在未来的某个任期的领导人日志中. 设大于T的最小任期U的领导人U没有这条日志.

- ```U```在参与选举时没有那条被提交的日志条目.(```candidate```和```leader```都不会删除或覆盖日志)
- 由于```T```把这条被提交的日志复制到了集群的大多数节点, 而```U```获得了大多数节点的选票. 那么至少有一个节点既拥有领导人T的日志, 又给U投票了.
- 这个投票者在给U投票时依然保存有这条日志条目, 因为中间任何领导人都有这条日志(根据我们的假设), 而```follower```只有和领导人冲突才会删除条目
- 那么当投票者拥有这条日志条目且给U投票时, 说明U的日志至少和投票者一样新, 这产生了矛盾. 下面根据日志 更 新的两种情况分别推出矛盾

1、当投票者和领导人U的最后一条日志任期号相同, 领导人U的日志至少和投票者一样长.

​	(如果相同索引位置的日志任期号相同, 那么之前的所有日志都是相匹配的.

​	一开始肯定满足这个特性, 然后在添加新日志时会检查之前日志是否匹配, 就维护了该特性.)

​	所以领导人U应该拥有投票者所有日志

2、当领导人U的最后一条日志任期号比投票者更大时, 肯定也比T更大.(因为投票者任期至少是T)

创建(领导人U最后一条日志)的之前的领导人K一定包含那条被提交的日志. 所以根据日志匹配特性, 领导人U和之前那个领导人K的日志是相匹配的, U一定包含那条被提交的日志.

(实质: 通过证明在领导人T之后U之前, 还有其他领导人提交过日志. 从而使用日志匹配特性)

### Part 2A: leader election

​	实现Raft leader选举和心跳(添加没有日志条目的rpc)。Part 2A的目标是选出一名领导人，如果没有任何故障，领导人将继续担任领导人，如果旧领导人失败或旧领导人的数据包丢失，则由新领导人接任。运行```go test -run 2A```来测试你的2A代码。

**Hint**

- 定义一个结构体保存每个日志条目的信息
- 补充```RequestVoteArgs```和```RequestVoteReply```结构体. 修改```Make()```来创建一个后台```goroutine```. 当他一段时间没收到其他```peer```的消息时, 发送```RequestVote rpc```来启动领导人选举.
- 要实现心跳，需要定义一个```AppendEntries RPC```结构体(尽管你可能还不需要所有的参数)，并让```leader```周期性地将它们发送出去。编写一个```AppendEntries RPC```处理程序方法，重置选举超时时间，这样当一个服务器已经当选时，其他服务器就不会再充当领导者了。
- 测试代码要求```leader```每秒发送心跳rpc不超过10次。
- 测试代码要求您的```Raft```在前一个```leader```失败后的五秒钟内选出一个新的```leader```(如果大多数同行仍然可以沟通)。然而，请记住，领导人选举可能需要多轮，以防出现分裂投票(如果分组丢失或候选人不幸选择了相同的随机退避时间，可能会发生这种情况)。您必须选择足够短的选举超时(以及心跳间隔)，以便选举很可能在5秒内完成，即使它需要多轮选举.
- 你需要编写周期性或延迟后执行操作的代码。最简单的方法是创建一个带有循环调用```time.Sleep()```的```goroutine```;查看```Make()```为此目的创建的ticker() goroutine。不要利用Go的```time.Timer```或```time.Ticker```。这很难正确使用。
- 别忘了实现```GetState()```。
- 测试代码在永久关闭实例时调用```Raft```的```rf.Kill()```。可以使用```rf.killed()```检查是否调用了```Kill()```。您可能希望在所有循环中执行此操作，以避免dead Raft实例打印令人困惑的消息。

**Implement**

- ```raft```节点进入循环, 检查自身是否应该开启一轮新的选举. 如果不应该, 那么需要启动一个超时计数器

**注意点**

- 请记住, 网络可以延迟```rpc```的请求和响应. 当你发送并发的```rpc```请求时, 网络可以重新排序请求和响应. 图2很好的指出了```rpc```处理程序需要注意的地方. 例如, ```rpc```处理程序需要忽略具有旧的```Term```的信息.但是图2没有仔细说明```rpc```应答的处理. 领导人在处理回复时需要小心谨慎:

​		它必须检查```term```在发送```rpc```后没有发生变化, 并且需要考虑并发的```rpc```对同一个```follower```的响应是否改变了```leader```的状态(例如```nextIndex```)

- 当收到心跳包时, 不应该简单得重置选举计时器并返回成功. 需要进行一些检查, 因为返回成功意味着告诉领导者, 它们的日志与领导者相匹配, 一直到```prevLogIndex```.
- 在收到心跳包时, 在```prevLogIndex```后面截断追随者的日志也是不正确的. 必须保留```leader```发送的条目后面的任何元素, 因为我们可能从```leader```那接收到一个过时的```AppendEntries RPC```
- 如果选举超时而没有从当前领导者接收```AppendEntries RPC```或给候选人投票: 转换为候选人。这是非常重要的, 因为一种普遍的做法是一旦收到```AppendEntries```或```RequestVote RPC```就重置超时计数器, 这会使系统的活跃性显著降低, 比如当节点拒绝一次投票请求时, 不应该重置自己的超时计数器. 此时是需要自己进行超时的!!
- 不允许将```commitindex```更新到一个之前任期的索引上去, 否则可能出现图```8```的情况. 只能更新到当前索引的条目上去
- 当接受```rpc```时, 看到一个旧的```term```并不是什么难事, 在图2中描述了对应的步骤. 但是在收到```rpc```回复时， 如果当前任期和发送```rpc```时的任期不同, 应该抛弃这条回复并直接返回.



### Part 2B: log ([hard](https://pdos.csail.mit.edu/6.824/labs/guidance.html))

- 你的第一个目标应该是通过```TestBasicAgree2B()```。首先实现```Start()```，然后编写代码通过```AppendEntries rpc```以发送和接收新的日志条目，如图2所示。发送每个刚被提交的```committed```日志到```applyCh```
- 在早期的```Lab 2B```测试中未能达成一致的一个方法是，即使领导人还活着，也要举行反复选举。寻找选举计时器管理中的bug，或者在赢得选举后没有立即发送心跳。
- 你的代码可能有循环来反复检查某些事件。不要让这些循环连续执行而不暂停，因为那样会减慢实现速度，导致测试失败。使用Go的条件变量，或者插入在每个循环迭代中插入```time.Sleep(10 * time.Millisecond)```



### Part 2C: persistence

​	如果基于```raft```的服务器重新启动，它应该在中断的地方恢复服务。这要求```Raft```保持在重启后仍然存在的持久状态。论文的图2提到了哪个状态应该是持久的。

​	真正的实现将在每次更改```Raft```时将其持久状态写入磁盘，并在重新启动后重新启动时从磁盘读取状态。你的实现不会使用磁盘;  相反，它将从一个```Persister```对象保存和恢复持久状态(请参见```persistent .go```)。调用```Raft.make()```时都会提供一个持久化对象，它最初保存```Raft```最近的持久化状态(如果有的话)。```Raft```应该从该持久化中初始化其状态，并在每次状态更改时使用它来保存其持久化状态。使用持久化对象的```ReadRaftState()```和```Save()```方法。

> 在```raft.go```中完成函数```persist()```和```readPersist()```。通过添加代码来保存和恢复持久状态。你需要将状态编码(或“序列化”)为字节数组，以便将其传递给```Persister```。使用labgob编码器;请参阅persist()和readPersist()中的注释。labgob类似于Go的gob编码器，但如果您尝试使用小写字段名称编码结构，则会打印错误消息。现在，将nil作为第二个参数传递给persister.Save()。在实现改变持久化状态的地方插入对persist()的调用。完成这些之后，如果实现的其他部分正确，就应该能通过所有的2C测试。



### Part 2D: log compaction

​	就目前的情况而言，重新启动的服务器会重放完整的```Raft```日志，以恢复其状态。然而，让一个长期运行的服务永远记住完整的```Raft```日志是不现实的。所以，您将修改```Raft```以与服务协作，这些服务不时地持久存储它们状态的“快照”，此时```Raft```将丢弃快照之前的日志条目。结果是持久化数据的数量更少，重启速度更快。然而，现在一个跟随者可能远远落后于```leader```，以至于```leader```已经丢弃了它需要追赶的日志条目; 然后```leader```必须发送一个快照以及从快照开始时的日志。扩展的```Raft```文件第7节概述了该方案; 你必须设计其细节。

​	您可能会发现，参考```Raft```交互图有助于理解复制的服务和```Raft```如何通信。

​	您的```Raft```必须提供以下功能，服务可以使用其状态的序列化快照进行调用:

```go
Snapshot(index int, snapshot []byte)
```

​	在```2D```中，测试代码会周期性地调用```Snapshot()```。在实验3中，您还将编写一个调用```Snapshot()```的键值对服务器; 快照将包含完整的键值对表。服务层在每一端(不仅仅是```leader```)上调用```Snapshot()```。



​	```index```参数表示快照中反映的最高日志条目。```Raft```应该丢弃在此之前的日志条目。您需要修改```Raft```代码，使其仅存储日志尾部。



​	您需要实现本文中讨论的```InstallSnapshot RPC```，它允许```Raft leader```告诉滞后的```Raft peer```用快照替换它的状态。您可能需要仔细考虑```InstallSnapshot```应该如何与图2中的状态和规则进行交互。

​	当追随者的```Raft```代码接收到```InstallSnapshot RPC```时，它可以使用```applyCh```将快照发送到```ApplyMsg```中的服务。```ApplyMsg```结构体定义已经包含了您将需要的字段(以及测试人员期望的字段)。请注意，这些快照只推进服务的状态，而不是使其向后移动。

​	如果服务器崩溃了，它必须从持久化的数据中重新启动。您的```Raft```应该持久化```Raft```状态和相应的快照。使用第二个参数给```persister.Save()```来保存快照。如果没有快照，传递```nil```作为第二个参数。

​	当服务器重启时，应用层读取持久化快照并恢复其保存的状态。

- 一个好的开始是修改代码，使其能够只存储从某个索引X开始的日志部分。最初，您可以将X设置为0并运行```2B/2C```测试。然后让```Snapshot(index)```先丢弃```index```前的日志，并设置```X = index```。如果一切顺利，你现在应该通过第一个```2D```测试。

- 您将无法将日志存储在Go切片中，也无法与Raft日志索引互换使用Go切片索引;

  你需要决定以哪种方式来索引日志(考虑被丢弃的日志部分)。

- 下一步: 如果```leader```没有更新```follower```所需的日志条目，则让它发送一个```InstallSnapshot RPC```。

- 在一个```InstallSnapshot RPC```中发送整个快照。不要实现图13中分割快照的偏移机制。

- ```Raft```必须以一种允许Go垃圾收集器释放和重用内存的方式丢弃旧的日志项; 这要求对丢弃的日志条目没有可达的引用(指针)。

- 即使日志被修剪了，你的实现仍然需要在```AppendEntries rpc```中的新条目之前正确地发送条目的术语和索引;这可能需要保存和引用最新快照的```lastIncludedTerm/lastIncludedIndex```(考虑是否应该持久化)。

- 对于没有-race的全套Lab 2测试(2A+2B+2C+2D)，合理的时间消耗是6分钟的实时时间和1分钟的CPU时间。当使用-race运行时，大约占用10分钟的实时时间和2分钟的CPU时间。



---

**LiveLocks**



你应该只在以下情况重置选举计时器

- 当接收到你认可的领导人的```AppendEntries RPC```时
- 你自己开始选举
- 当你给某个```Candidate```投票时,

最后一条尤为重要, 在不可靠的网络中, ```follower```拥有不同的日志, 只有少部分的服务器拥有最新的日志. 如果每次有人请求投票你都重置选举计数器, 那么拥有最新日志的服务器也许总是在开始选举前被打断导致无法选举.

而且, 如果你正在开始一次选举, 而超时计数器再次到期, 那就应该开始另一场选举, 这是为了避免系统因延迟或丢弃```rpc```

而且注意图2中的这句话

```sql
If RPC request or response contains term T > currentTerm: set currentTerm = T, convert to follower (§5.1)
```

例如，如果您已经在当前任期投票，并且即将到来的请求```vote RPC```有一个比您更高的任期，您应该首先采用他们的任期(从而重置```votedFor```)，然后处理RPC，这将导致您授予投票!

**Incorrect RPC handlers**

尽管图2精确地说明了每个RPC处理程序应该做什么，一些微妙之处仍然很容易被忽略。

下面是一些我们反复看到的细节，您应该在实现中关注它们:

- 如果一个步骤显示```“reply false”```，这意味着你应该立即回复，而不是执行任何后续步骤。
- 如果你得到了一个```AppendEntries RPC```，它的```prevLogIndex```指向日志末尾之后的地方，你应该像处理有该条目但词条不匹配的情况一样处理它(即回复```false```)。
- 即使leader没有发送任何条目，RPC处理程序也应该被执行。
- ```AppendEntries```的最后一步(第5步)中的最小值是必须的，它需要用最后一个新条目的索引来计算。仅仅有一个在```lastApplied```和```commitIndex```之间应用日志的函数是不够的，它会在到达日志末尾时停止。这是因为在leader发送给你的条目之后，你的日志中的条目可能与leader的日志不同(它们都与你的日志中的条目相匹配)。因为#3规定，只有在有冲突条目时才会截断日志，这些条目不会被删除，而且如果```leaderCommit```超出了leader发送给你的条目，你可能会应用不正确的条目。
- 完全按照5.4节的描述实现“最新日志”检查是很重要的。

#### Failure to follow The Rules

虽然```Raft```论文非常明确地说明了如何实现每个```RPC```处理程序，但它也没有说明许多规则和不变量的实现。这些在图2右侧的```“Rules for Servers”```块中列出。虽然其中一些规则不言自明，但也有一些要求你非常仔细地设计你的应用程序，以免违反这些规则:

- 如果```commitIndex > lastApplied```在执行期间的任何时刻，您应该应用特定的日志条目。直接执行这个操作并不重要(例如，在```AppendEntries RPC```处理程序中)，但重要的是要确保这个应用程序只由一个实体执行。具体来说，您需要有一个专用的“应用程序”，或者对这些应用程序进行锁定，以便其他一些例程不会检测到需要应用的条目，也不会尝试应用。因为必须保证日志是顺序发送的
- 请确保定期检查```commitIndex > lastApplied```，或者在```commitIndex```更新后(即在```matchIndex```更新后)。例如，如果在向节点发送```AppendEntries```的同时检查了```commitIndex```，那么在应用刚刚发送的条目并得到确认之前，可能必须等到下一个条目被添加到日志中。
- 如果leader发送了一个AppendEntries RPC请求，并且它被拒绝了，但不是因为日志不一致(只有在我们的term已经过时才会发生)，那么你应该立即退出，不更新```nextIndex```。如果你这样做了，如果你立即再次当选，你可以与```nextIndex```的重置竞争。
- leader不允许将```commitIndex```更新到之前```Term```的某个位置。因此，正如规则所说，你需要特别检查```log[N].term == currentTerm```。这是因为如果条目不是在当前任期内提交的，那么```Raft```领导人无法确定条目是否已经提交(并且在未来永远不会更改)。本文中的图8说明了这一点。

​	```nextIndex```和```matchIndex```之间的区别是一个常见的混淆来源。特别地，你可能会注意到```matchIndex = nextIndex - 1```，并没有实现```matchIndex```。这样不安全。虽然```nextIndex```和```matchIndex```通常在同一时间更新为一个相似的值(具体来说，```nextIndex``` = ```matchIndex + 1```)，但两者的目的完全不同。```nextIndex```是对```leader```和```follower```共享的前缀的猜测。它通常是相当乐观的(我们分享所有的东西)，只有在消极的反应时才会回退。例如，当一个```leader```刚刚当选时，```nextIndex```被设置为日志末尾的```index index```。在某种程度上，```nextIndex```用于提高性能——你只需要将这些内容发送到该节点即可。

使用```matchIndex```是为了安全。它是对```leader```与给定```follower```共享的日志前缀的保守度量。```matchIndex```不能设置得太大，因为这可能会导致```commitIndex```向前移动太远。这就是为什么```matchIndex```被初始化为-1(也就是说，我们同意没有前缀)，并且只有当一个```follower```积极地承认``AppendEntries RPC```时才更新。

#### Term confusion


```Term```混淆是指服务器被来自旧```Term```的rpc混淆。通常，在接收RPC时这不是问题，因为图2中的规则确切地说明了当您看到旧```Term```时应该做什么。然而，图2通常没有讨论当您得到旧的RPC回复时应该做什么。根据经验，我们发现目前最简单的做法是，首先记录回复中的词条(可能比你现在的词条高)，然后将现在的```Term```与你原来的RPC发送的```Term```进行比较。如果两者不同，请放弃回复并返回。只有当两个```Term```相同时，您才应该继续处理答复。你可以通过一些聪明的协议推理来做进一步的优化，但这种方法似乎工作得很好。如果不这样做，就会走上一条充满血、汗、泪和绝望的漫长而曲折的道路。

另一个相关但不同的问题是，假设你的状态在发送RPC和收到回复之间没有改变。一个很好的例子是在收到RPC响应时设置```matchIndex = nextIndex - 1```或```matchIndex = len(log)```。这是不安全的，因为这两个值可能在你发送RPC之后都已经更新了。相反，正确的做法是更新```matchIndex```为```prevLogIndex + len(entries[])```，其值与你之前在RPC中发送的参数相同。



#### An aside on optimizations

​	```Raft```论文包含了几个可选的有趣特性。在```6.824```中，我们要求学生实现其中的两个:日志压缩(第7节)和加速日志回溯(第8页的左上角)。前者是避免日志无约束地增长所必需的，后者有助于使陈旧的跟踪者快速更新。

​	这些特性不是“核心Raft”的一部分，因此在论文中没有得到像主要共识协议那样多的关注。日志压缩被相当彻底地覆盖了(在图13中)，但是省略了一些设计细节，如果你太随意地阅读它，你可能会错过:

- 在对应用程序状态进行快照时，需要确保应用程序状态对应于Raft日志中某个已知索引后面的状态。这意味着应用程序要么需要与```raft```通信快照对应的索引，要么```raft```需要延迟应用额外的日志条目，直到快照完成。

- 本文没有讨论当服务器崩溃时的恢复协议，现在涉及到快照。特别是，如果Raft状态和快照是分开提交的，服务器可能会在持久化快照和持久化更新后的Raft状态之间崩溃。这是一个问题，因为图13中的步骤7规定必须丢弃快照覆盖的```Raft```日志。

  如果当服务器恢复时，它读取更新的快照，但读取过时的日志，那么它可能最终应用快照中已经包含的一些日志条目。这是因为commitIndex和lastApplied没有被持久化，所以Raft不知道那些日志条目已经被应用了。解决这个问题的方法是向```Raft```引入一个持久状态，它记录```raft```的持久日志中的第一个条目对应的“真实”索引。然后可以将其与加载快照的```lastIncludedIndex```进行比较，以确定要丢弃日志头部的哪些元素。

加速日志回溯优化没有详细说明，这可能是因为作者认为大多数部署都不需要它。从文本中不清楚，从客户端发回的冲突索引和术语应该如何被领导者用来决定使用什么nextIndex。我们相信作者可能希望你遵循的协议是:

- 如果一个follower的日志中没有prevLogIndex，它应该返回conflictIndex = len(log)和conflictTerm = None。
- 如果一个追随者的日志中确实有prevLogIndex，但术语不匹配，它应该返回conflictTerm = log[prevLogIndex]。Term，然后在其日志中搜索词条Term等于conflictTerm的第一个索引。
- 在收到冲突响应后，领导者应该首先在其日志中搜索conflictTerm。如果它在日志中发现带有该项的条目，它应该将nextIndex设置为该项中最后一个条目的索引之上的那个。
- 如果没有找到包含该项的条目，则应该设置nextIndex = conflictIndex。

一个折衷的解决方案是只使用conflictIndex(并忽略conflictTerm)，这简化了实现，但是领导者有时会向追随者发送更多的日志条目，而不是严格必要的使它们更新。

```cpp
[{Command:<nil> Term:1 Index:9} {Command:7306608271526379903 Term:1 Index:10} {Command:7962203368847474885 Term:1 Index:11} 
{Command:60813005416490648 Term:1 Index:12} 
{Command:60813005416490648 Term:5 Index:13}]
```

